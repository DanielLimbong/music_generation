Epoch 1/3:   0%|          | 0/9350 [00:00<?, ?it/s]/tmp/ipykernel_30/1236129221.py:116: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
Epoch 1/3:   1%|          | 77/9350 [00:00<00:12, 765.16it/s]
Step 0: input_ids shape: torch.Size([2, 256]), target_ids shape: torch.Size([2, 256])
Skipping layer 0 due to empty input slice.
Skipping layer 1 due to empty input slice.
Skipping layer 2 due to empty input slice.
Skipping layer 3 due to empty input slice.
Error at step 0: type_as() missing 1 required positional arguments: "other"
Step 1: input_ids shape: torch.Size([2, 256]), target_ids shape: torch.Size([2, 256])
Skipping layer 0 due to empty input slice.
Skipping layer 1 due to empty input slice.
Skipping layer 2 due to empty input slice.
Skipping layer 3 due to empty input slice.
Error at step 1: type_as() missing 1 required positional arguments: "other"
Step 2: input_ids shape: torch.Size([2, 256]), target_ids shape: torch.Size([2, 256])
Skipping layer 0 due to empty input slice.
Skipping layer 1 due to empty input slice.
Skipping layer 2 due to empty input slice.
Skipping layer 3 due to empty input slice.
Error at step 2: type_as() missing 1 required positional arguments: "other"
Step 3: input_ids shape: torch.Size([2, 256]), target_ids shape: torch.Size([2, 256])
Skipping layer 0 due to empty input slice.
Skipping layer 1 due to empty input slice.
Skipping layer 2 due to empty input slice.
Skipping layer 3 due to empty input slice.
Error at step 3: type_as() missing 1 required positional arguments: "other"
Step 4: input_ids shape: torch.Size([2, 256]), target_ids shape: torch.Size([2, 256])
Skipping layer 0 due to empty input slice.
Skipping layer 1 due to empty input slice.
Skipping layer 2 due to empty input slice.
Skipping layer 3 due to empty input slice.